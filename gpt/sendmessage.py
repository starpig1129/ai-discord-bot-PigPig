import os
import json
import faiss
from gpt.gpt_response_gen import generate_response
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.docstore.in_memory import InMemoryDocstore
system_prompt='''
                You(assistant) are a helpful, 
                respectful and honest AI chatbot named ğŸ–ğŸ–. 
                You are talking in a funny way to a human(user).
                If you don't know the answer to a question, don't share false information.
                Use the information provided to answer the questions in <<>>.
                You are made by æ˜Ÿè±¬<@597028717948043274>
                Always answer in Traditional Chinese.
                '''
# åˆå§‹åŒ– Hugging Face åµŒå…¥æ¨¡å‹
hf_embeddings_model = "sentence-transformers/all-MiniLM-L6-v2"
embeddings = HuggingFaceEmbeddings(model_name=hf_embeddings_model)
# å‰µå»ºæˆ–åŠ è¼‰ FAISS ç´¢å¼•
def create_faiss_index():
    embedding_size = 384
    index = faiss.IndexFlatL2(embedding_size)
    docstore = InMemoryDocstore({})
    index_to_docstore_id = {}
    return FAISS(embeddings, index, docstore, index_to_docstore_id)

vector_store = create_faiss_index()
def load_and_index_dialogue_history(dialogue_history_file):
    if not os.path.exists(dialogue_history_file):
        return

    with open(dialogue_history_file, 'r', encoding='utf-8') as file:
        dialogue_history = json.load(file)

    for channel_id, messages in dialogue_history.items():
        texts = [msg["content"] for msg in messages if msg["role"] == "user"]
        metadatas = [{"text": text} for text in texts]
        vector_store.add_texts(texts, metadatas)

def save_vector_store(vector_store, path):
    vector_store.save(path)

def load_vector_store(path):
    if os.path.exists(path):
        vector_store.index = faiss.read_index(path)
        vector_store.index = faiss.index_cpu_to_all_gpus(vector_store.index)  # ä½¿ç”¨ GPU åŠ é€Ÿ
    else:
        print("å‘é‡è³‡æ–™åº«æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°‡å‰µå»ºæ–°çš„è³‡æ–™åº«")

def search_vector_database(query):
    try:
        results = vector_store.similarity_search(query, k=5)
        related_data = "\n".join([result.metadata['text'] for result in results])
        return related_data
    except:
        return ''

async def gpt_message(message_to_edit,message,prompt):
    
    channel = message.channel
        
    # å¾å‘é‡è³‡æ–™åº«å°‹æ‰¾ç›¸é—œè³‡æ–™
    related_data = search_vector_database(prompt)  # ä½¿ç”¨ LangChain æœå°‹ç›¸é—œè³‡æ–™
    # è®€å–è©²è¨Šæ¯é »é“æœ€è¿‘çš„æ­·å²ç´€éŒ„
    history = []
    async for msg in channel.history(limit=10):
        history.append(msg)
    history.reverse()
    history = history[:-2]
    history_dict = [{"role": "user" if msg.author != message.guild.me else "assistant", "content": msg.content} for msg in history]
    # çµ„åˆè³‡æ–™
    combined_prompt = f"Information:<<{related_data}>>User: {prompt}"
    try:
        responses = ""
        thread,streamer = await generate_response(combined_prompt, system_prompt,history_dict)
        buffer_size = 40  # è®¾ç½®ç¼“å†²åŒºå¤§å°
        responsesall = ""
        for response in streamer:
            print(response, end="", flush=True)
            responses += response

            if len(responses) >= buffer_size:
                responsesall+=responses
                await message_to_edit.edit(content=responsesall)  # ä¿®æ”¹æ¶ˆæ¯å†…å®¹
                responses = ""  # æ¸…ç©º responses å˜é‡
        print("çµæŸ")
        # å¤„ç†å‰©ä½™çš„æ–‡æœ¬
        responsesall+=responses
        responsesall = responsesall.replace('<|eot_id|>',"")
        await message_to_edit.edit(content=responsesall)  # ä¿®æ”¹æ¶ˆæ¯å†…å®¹
        thread.join()
        return responsesall
    except Exception as e:
        print(e)
# åœ¨æ¨¡å¡ŠåŠ è¼‰æ™‚ç´¢å¼•å°è©±æ­·å²ä¸¦è¼‰å…¥å‘é‡è³‡æ–™åº«
load_vector_store('./data/vector_store')
load_and_index_dialogue_history('./data/dialogue_history.json')