"""å•Ÿå‹•æ—¥èªŒå„ªåŒ–ç®¡ç†å™¨

æä¾›è¨˜æ†¶ç³»çµ±å•Ÿå‹•æ™‚çš„æ—¥èªŒèšåˆå’Œç°¡åŒ–åŠŸèƒ½ï¼Œ
æ¸›å°‘å†—é¤˜çš„ INFO ç´šåˆ¥æ—¥èªŒè¼¸å‡ºï¼ŒåŒæ™‚ä¿æŒé™¤éŒ¯è³‡è¨Šçš„å®Œæ•´æ€§ã€‚
"""

import logging
import time
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Set
from pathlib import Path


@dataclass
class StartupMetrics:
    """å•Ÿå‹•æŒ‡æ¨™è³‡æ–™é¡åˆ¥"""
    total_indices: int = 0
    loaded_indices: int = 0
    failed_indices: int = 0
    gpu_memory_checks: int = 0
    gpu_memory_warnings: int = 0
    startup_time: float = 0.0
    batch_count: int = 0
    errors: List[str] = field(default_factory=list)


class StartupLogger:
    """å•Ÿå‹•æ—¥èªŒç®¡ç†å™¨
    
    è² è²¬åœ¨æ©Ÿå™¨äººå•Ÿå‹•æœŸé–“èšåˆå’Œç°¡åŒ–æ—¥èªŒè¼¸å‡ºï¼Œ
    é¿å…ç”¢ç”Ÿéå¤šçš„ INFO ç´šåˆ¥è¨Šæ¯ã€‚
    """
    
    def __init__(self, logger: logging.Logger):
        """åˆå§‹åŒ–å•Ÿå‹•æ—¥èªŒç®¡ç†å™¨
        
        Args:
            logger: åŸå§‹ logger å¯¦ä¾‹
        """
        self.logger = logger
        self.metrics = StartupMetrics()
        self.start_time = time.time()
        self.is_startup_mode = True
        self.last_gpu_memory_log = 0.0
        self.gpu_memory_log_interval = 30.0  # 30ç§’é–“éš”
        
        # è¿½è¹¤å·²è™•ç†çš„é …ç›®ï¼Œé¿å…é‡è¤‡æ—¥èªŒ
        self.processed_channels: Set[str] = set()
        self.gpu_warnings_shown: Set[str] = set()
        
    def start_startup_phase(self) -> None:
        """é–‹å§‹å•Ÿå‹•éšæ®µ"""
        self.is_startup_mode = True
        self.start_time = time.time()
        self.logger.info("ğŸš€ è¨˜æ†¶ç³»çµ±å•Ÿå‹•ä¸­...")
        
    def end_startup_phase(self) -> None:
        """çµæŸå•Ÿå‹•éšæ®µä¸¦è¼¸å‡ºæ‘˜è¦"""
        self.is_startup_mode = False
        self.metrics.startup_time = time.time() - self.start_time
        self._log_startup_summary()
        
    def log_gpu_memory_check(
        self, 
        total_mb: int, 
        free_mb: int, 
        used_percent: float,
        force_log: bool = False
    ) -> None:
        """è¨˜éŒ„ GPU è¨˜æ†¶é«”æª¢æŸ¥ï¼ˆç¯€æµè™•ç†ï¼‰
        
        Args:
            total_mb: ç¸½è¨˜æ†¶é«”ï¼ˆMBï¼‰
            free_mb: å¯ç”¨è¨˜æ†¶é«”ï¼ˆMBï¼‰
            used_percent: ä½¿ç”¨ç‡ç™¾åˆ†æ¯”
            force_log: æ˜¯å¦å¼·åˆ¶è¨˜éŒ„æ—¥èªŒ
        """
        self.metrics.gpu_memory_checks += 1
        current_time = time.time()
        
        # ç¯€æµï¼šåªåœ¨é–“éš”æ™‚é–“å¾Œæˆ–å¼·åˆ¶è¨˜éŒ„æ™‚è¼¸å‡º
        if (force_log or 
            current_time - self.last_gpu_memory_log > self.gpu_memory_log_interval):
            
            if self.is_startup_mode:
                # å•Ÿå‹•æ¨¡å¼ï¼šç°¡åŒ–æ—¥èªŒ
                self.logger.debug(
                    f"GPU è¨˜æ†¶é«”: {free_mb}MB å¯ç”¨ / {total_mb}MB ç¸½è¨ˆ "
                    f"(ä½¿ç”¨ç‡: {used_percent:.1f}%)"
                )
            else:
                # æ­£å¸¸æ¨¡å¼ï¼šè©³ç´°æ—¥èªŒ
                self.logger.info(
                    f"GPU è¨˜æ†¶é«”ç‹€æ…‹: ç¸½è¨ˆ {total_mb}MB, "
                    f"å¯ç”¨ {free_mb}MB, ä½¿ç”¨ç‡ {used_percent:.1f}%"
                )
            
            self.last_gpu_memory_log = current_time
            
        # è¨˜éŒ„è­¦å‘Šï¼ˆå¦‚æœéœ€è¦ï¼‰
        if used_percent > 85.0:
            warning_key = f"high_usage_{used_percent:.0f}"
            if warning_key not in self.gpu_warnings_shown:
                self.logger.warning(f"GPU è¨˜æ†¶é«”ä½¿ç”¨ç‡éé«˜: {used_percent:.1f}%")
                self.gpu_warnings_shown.add(warning_key)
                self.metrics.gpu_memory_warnings += 1
                
    def log_index_loading_start(self, total_count: int) -> None:
        """è¨˜éŒ„ç´¢å¼•è¼‰å…¥é–‹å§‹
        
        Args:
            total_count: ç¸½ç´¢å¼•æ•¸é‡
        """
        self.metrics.total_indices = total_count
        if total_count == 0:
            self.logger.info("ğŸ“‚ æ²’æœ‰æ‰¾åˆ°ç¾æœ‰çš„ç´¢å¼•æª”æ¡ˆ")
        else:
            self.logger.info(f"ğŸ“‚ æ‰¾åˆ° {total_count} å€‹ç¾æœ‰ç´¢å¼•ï¼Œé–‹å§‹è¼‰å…¥...")
            
    def log_batch_progress(
        self, 
        batch_num: int, 
        total_batches: int, 
        batch_loaded: int,
        batch_failed: int
    ) -> None:
        """è¨˜éŒ„æ‰¹æ¬¡é€²åº¦ï¼ˆç°¡åŒ–ç‰ˆï¼‰
        
        Args:
            batch_num: ç•¶å‰æ‰¹æ¬¡ç·¨è™Ÿ
            total_batches: ç¸½æ‰¹æ¬¡æ•¸
            batch_loaded: æœ¬æ‰¹æ¬¡è¼‰å…¥æˆåŠŸæ•¸
            batch_failed: æœ¬æ‰¹æ¬¡è¼‰å…¥å¤±æ•—æ•¸
        """
        self.metrics.loaded_indices += batch_loaded
        self.metrics.failed_indices += batch_failed
        self.metrics.batch_count = batch_num
        
        # åªåœ¨é—œéµç¯€é»è¨˜éŒ„é€²åº¦ï¼ˆé¿å…éå¤šæ—¥èªŒï¼‰
        if batch_num == 1 or batch_num == total_batches or batch_num % 5 == 0:
            progress_percent = (batch_num / total_batches) * 100
            self.logger.debug(
                f"ğŸ“Š è¼‰å…¥é€²åº¦: {batch_num}/{total_batches} æ‰¹æ¬¡ "
                f"({progress_percent:.0f}%) - "
                f"æˆåŠŸ {self.metrics.loaded_indices}ï¼Œ"
                f"å¤±æ•— {self.metrics.failed_indices}"
            )
            
    def log_channel_index_ready(self, channel_id: str, is_new: bool = False) -> None:
        """è¨˜éŒ„é »é“ç´¢å¼•æº–å‚™å°±ç·’ï¼ˆå»é‡è™•ç†ï¼‰
        
        Args:
            channel_id: é »é“ ID
            is_new: æ˜¯å¦ç‚ºæ–°å»ºç´¢å¼•
        """
        if channel_id in self.processed_channels:
            return
            
        self.processed_channels.add(channel_id)
        
        if self.is_startup_mode:
            # å•Ÿå‹•æ¨¡å¼ï¼šåƒ… debug ç´šåˆ¥
            status = "æ–°å»º" if is_new else "è¼‰å…¥"
            self.logger.debug(f"é »é“ {channel_id} ç´¢å¼•å·²{status}")
        else:
            # æ­£å¸¸æ¨¡å¼ï¼šinfo ç´šåˆ¥
            status = "æ–°å»º" if is_new else "è¼‰å…¥"
            self.logger.info(f"é »é“ {channel_id} çš„å‘é‡ç´¢å¼•å·²æº–å‚™å°±ç·’ï¼ˆ{status}ï¼‰")
            
    def log_gpu_index_migration(self, channel_id: str, estimated_mb: int) -> None:
        """è¨˜éŒ„ GPU ç´¢å¼•é·ç§»ï¼ˆç°¡åŒ–ï¼‰
        
        Args:
            channel_id: é »é“ ID
            estimated_mb: é ä¼°è¨˜æ†¶é«”ä½¿ç”¨é‡
        """
        if self.is_startup_mode:
            # å•Ÿå‹•æ¨¡å¼ï¼šç°¡åŒ–æ—¥èªŒ
            self.logger.debug(f"ç´¢å¼• {channel_id} å·²ç§»è‡³ GPU ({estimated_mb}MB)")
        else:
            # æ­£å¸¸æ¨¡å¼ï¼šè©³ç´°æ—¥èªŒ
            self.logger.info(f"ç´¢å¼•å·²ç§»è‡³ GPUï¼ˆé ä¼°è¨˜æ†¶é«”: {estimated_mb}MBï¼‰")
            
    def log_error(self, error_msg: str) -> None:
        """è¨˜éŒ„éŒ¯èª¤è¨Šæ¯
        
        Args:
            error_msg: éŒ¯èª¤è¨Šæ¯
        """
        self.metrics.errors.append(error_msg)
        self.logger.error(error_msg)
        
    def log_warning(self, warning_msg: str, deduplicate: bool = True) -> None:
        """è¨˜éŒ„è­¦å‘Šè¨Šæ¯
        
        Args:
            warning_msg: è­¦å‘Šè¨Šæ¯
            deduplicate: æ˜¯å¦å»é‡
        """
        if deduplicate and warning_msg in self.gpu_warnings_shown:
            return
            
        if deduplicate:
            self.gpu_warnings_shown.add(warning_msg)
            
        self.logger.warning(warning_msg)
        
    def _log_startup_summary(self) -> None:
        """è¨˜éŒ„å•Ÿå‹•æ‘˜è¦"""
        success_rate = 0.0
        if self.metrics.total_indices > 0:
            success_rate = (self.metrics.loaded_indices / self.metrics.total_indices) * 100
            
        # ä¸»è¦æ‘˜è¦
        self.logger.info(
            f"âœ… è¨˜æ†¶ç³»çµ±å•Ÿå‹•å®Œæˆ "
            f"(è€—æ™‚: {self.metrics.startup_time:.1f}ç§’)"
        )
        
        # ç´¢å¼•è¼‰å…¥æ‘˜è¦
        if self.metrics.total_indices > 0:
            self.logger.debug(
                f"ğŸ“‹ ç´¢å¼•è¼‰å…¥æ‘˜è¦: "
                f"{self.metrics.loaded_indices}/{self.metrics.total_indices} æˆåŠŸ "
                f"({success_rate:.1f}%)ï¼Œ"
                f"å…±è™•ç† {self.metrics.batch_count} å€‹æ‰¹æ¬¡"
            )
        else:
            self.logger.info("ğŸ“‹ ç„¡ç¾æœ‰ç´¢å¼•éœ€è¦è¼‰å…¥")
            
        # GPU è¨˜æ†¶é«”æ‘˜è¦
        if self.metrics.gpu_memory_checks > 0:
            self.logger.debug(
                f"ğŸ”§ GPU è¨˜æ†¶é«”æª¢æŸ¥: {self.metrics.gpu_memory_checks} æ¬¡ï¼Œ"
                f"è­¦å‘Š: {self.metrics.gpu_memory_warnings} æ¬¡"
            )
            
        # éŒ¯èª¤æ‘˜è¦
        if self.metrics.errors:
            self.logger.warning(f"âš ï¸  å•Ÿå‹•æœŸé–“ç™¼ç”Ÿ {len(self.metrics.errors)} å€‹éŒ¯èª¤")
            for i, error in enumerate(self.metrics.errors[:3], 1):  # æœ€å¤šé¡¯ç¤º3å€‹éŒ¯èª¤
                self.logger.warning(f"   {i}. {error}")
            if len(self.metrics.errors) > 3:
                self.logger.warning(f"   ... é‚„æœ‰ {len(self.metrics.errors) - 3} å€‹éŒ¯èª¤")


class StartupLoggerManager:
    """å•Ÿå‹•æ—¥èªŒç®¡ç†å™¨å–®ä¾‹"""
    
    _instance: Optional[StartupLogger] = None
    
    @classmethod
    def get_instance(cls, logger: Optional[logging.Logger] = None) -> Optional[StartupLogger]:
        """å–å¾—å•Ÿå‹•æ—¥èªŒç®¡ç†å™¨å¯¦ä¾‹
        
        Args:
            logger: logger å¯¦ä¾‹ï¼ˆé¦–æ¬¡å‘¼å«æ™‚éœ€è¦ï¼‰
            
        Returns:
            StartupLogger å¯¦ä¾‹æˆ– None
        """
        if cls._instance is None and logger is not None:
            cls._instance = StartupLogger(logger)
        return cls._instance
    
    @classmethod
    def reset(cls) -> None:
        """é‡ç½®å¯¦ä¾‹ï¼ˆç”¨æ–¼æ¸¬è©¦ï¼‰"""
        cls._instance = None


def get_startup_logger(logger: Optional[logging.Logger] = None) -> Optional[StartupLogger]:
    """å–å¾—å•Ÿå‹•æ—¥èªŒç®¡ç†å™¨çš„ä¾¿åˆ©å‡½æ•¸
    
    Args:
        logger: logger å¯¦ä¾‹
        
    Returns:
        StartupLogger å¯¦ä¾‹æˆ– None
    """
    return StartupLoggerManager.get_instance(logger)